# 2-1 데이터 로드 및 전처리
import tensorflow as tf
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_valid, y_valid) = mnist.load_data()
print(x_train.shape, y_train.shape)
print(x_valid.shape, y_valid.shape)

# 샘플 이미지 출력
import matplotlib.pylab as plt
def plot_image(data, idx):
  plt.figure(figsize = (5,5))
  plt.imshow(data[idx],cmap = 'gray')
  plt.axis('off')
  plt.show()

plot_image(x_train, 0)

# 정규화(Normalization)
print(x_train.min(), x_train.max())
print(x_valid.min(), x_valid.max())

x_train = x_train / 255.0
x_valid = x_valid / 255.0

print(x_train.min(), x_train.max())
print(x_valid.min(), x_valid.max())

# 채널 추가
print(x_train.shape, x_valid.shape)
x_train_in = x_train[..., tf.newaxis]
x_valid_in = x_valid[..., tf.newaxis]

print(x_train_in.shape, x_valid_in.shape)

# Sequential API를 사용해 sample model 생성


model = tf.keras.Sequential([
                             tf.keras.layers.Conv2D(32,(3,3), activation = 'relu',
                                                    input_shape = (28,28,1), name = 'conv'),
                             tf.keras.layers.MaxPooling2D((2,2), name = 'pool'),
                             tf.keras.layers.Flatten(),
                             tf.keras.layers.Dense(10, activation = 'softmax'),
])

# 모델 컴파일 및 모델 훈련
model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(x_train_in, y_train,
                    validation_data = (x_valid_in, y_valid),
                    epochs = 10)
                    
model.evaluate(x_valid_in, y_valid)

def plot_loss_acc(history, epoch):
  loss, val_loss = history.history['loss'], history.history['val_loss']
  acc, val_acc = history.history['accuracy'], history.history['val_accuracy']

  fig, axes = plt.subplots(1, 2, figsize = (12,4))

  axes[0].plot(range(1, epoch + 1), loss, label = 'Training')
  axes[0].plot(range(1, epoch + 1), val_loss, label = 'Validation')
  axes[0].legend(loc = 'best')
  axes[0].set_title('Loss')

  axes[1].plot(range(1, epoch + 1), acc, label = 'Training')
  axes[1].plot(range(1, epoch + 1), val_acc, label = 'Validation')
  axes[1].legend(loc = 'best')
  axes[1].set_title('Accuracy')

  plt.show()

plot_loss_acc(history, 10)

model.summary()
model.input
model.output
model.layers

# 첫번째 레이어 가중치
model.layers[0].weights

# 첫번째 레이어 커널 가중치
model.layers[0].kernel

# 첫번째 레이어 bias 가중치
model.layers[0].bias,

# 레이어 이름 사용하여 레이어 선택
model.get_layer('conv')

# 06 객체 탐지
import tensorflow as tf
import tensorflow_hub as tfhub

# 샘플 이미지 다운로드
img_path = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Gangnam_Seoul_January_2009.jpg/1280px-Gangnam_Seoul_January_2009.jpg'

img = tf.keras.utils.get_file(fname = 'gangnam', origin = img_path)
img = tf.io.read_file(img) # 파일 객체를 string으로 변환.
img = tf.image.decode_jpeg(img, channels = 3) # 문자(string)를 숫자(unit8) 텐서로 변환
img = tf.image.convert_image_dtype(img, tf.float32) # 0~1 범위로 정규화

import matplotlib.pylab as plt
plt.figure(figsize = (15, 10))
plt.imshow(img)

# 가장 앞쪽으로 새로운 축을 추가(사전학습모델이 배치크기를 포함해서 4차원 텐서를 입력받으므로)
img_input = tf.expand_dims(img, 0) # batch_size 추가
img_input.shape

# TensorFlow Hub에서 모델 가져오기 - Fater R-CNN + InceptionResNet V2
model = tfhub.load("https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1") # 홈페이지에서 URL copy 해오면 됨!

# 모델의 시그니처(용도) 확인
model.signatures.keys()

# 객체탐지 모델 생성
obj_detector = model.signatures['default']
obj_detector

# 모델을 이용하여 예측(추론)
result = obj_detector(img_input)
result.keys()

# 탐지한 객체의 개수
len(result['detection_scores'])

# 객체 탐지 결과를 시각화
boxes = result["detection_boxes"] # Bounding Box 좌표 예측 값
labels = result['detection_class_entities'] # 분류 예측 값
scores = result["detection_scores"] # 신뢰도

# 샘플 이미지 가로 세로 크기
img_height, img_width = img.shape[0], img.shape[1]

# 탐지할 최대 객체의 수
obj_to_detect = 10

# 시각화
plt.figure(figsize = (15, 10))
for i in range(min(obj_to_detect, boxes.shape[0])):
  if scores[i] >= 0.2:
    (ymax, xmin, ymin, xmax) = (boxes[i][0]*img_height, boxes[i][1]*img_width,
                                boxes[i][2]*img_height, boxes[i][3]*img_width)

    plt.imshow(img)
    plt.plot([xmin, xmax, xmax, xmin, xmin], [ymin, ymin, ymax, ymax, ymin],
             color = 'yellow', linewidth = 2)
    class_name = labels[i].numpy().decode('utf-8')
    infer_score = int(scores[i].numpy() * 100)
    annotation = "{}: {}%".format(class_name, infer_score)
    plt.text(xmin + 10, ymax + 20, annotation,
             color = 'white', backgroundcolor = 'blue', fontsize = 10) 
             
             
